{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xxf076RztkZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFTxB3Pypb4v",
        "colab_type": "code",
        "outputId": "ab0391ea-22e0-49d8-c5c3-29adae7ac1c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "from pandas import read_csv\n",
        "from datetime import datetime\n",
        "\n",
        "def parse(x):\n",
        "\treturn datetime.strptime(x, '%Y %m %d %H')\n",
        "\n",
        "dataset = read_csv('./data/beijing.csv',  parse_dates = [['year', 'month', 'day', 'hour']], index_col=0, date_parser=parse)\n",
        "\n",
        "dataset.drop('No', axis=1, inplace=True)\n",
        "dataset.columns = ['pollution', 'dew', 'temp', 'press', 'wnd_dir', 'wnd_spd', 'snow', 'rain']\n",
        "dataset.index.name = 'date'\n",
        "dataset['pollution'].fillna(0, inplace=True)\n",
        "dataset = dataset[24:]\n",
        "print(dataset.head(5))\n",
        "\n",
        "dataset.to_csv('./data/pollution.csv')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                     pollution  dew  temp   press wnd_dir  wnd_spd  snow  rain\n",
            "date                                                                          \n",
            "2010-01-02 00:00:00      129.0  -16  -4.0  1020.0      SE     1.79     0     0\n",
            "2010-01-02 01:00:00      148.0  -15  -4.0  1020.0      SE     2.68     0     0\n",
            "2010-01-02 02:00:00      159.0  -11  -5.0  1021.0      SE     3.57     0     0\n",
            "2010-01-02 03:00:00      181.0   -7  -5.0  1022.0      SE     5.36     1     0\n",
            "2010-01-02 04:00:00      138.0   -7  -5.0  1022.0      SE     6.25     2     0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svGvSyeGrtsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from pandas import read_csv\n",
        "# from matplotlib import pyplot\n",
        "\n",
        "# dataset = read_csv('pollution.csv', header=0, index_col=0)\n",
        "# values = dataset.values\n",
        "# # specify columns to plot\n",
        "# groups = [0, 1, 2, 3, 5, 6, 7]\n",
        "# i = 1\n",
        "# # plot each column\n",
        "# pyplot.figure()\n",
        "# for group in groups:\n",
        "# \tpyplot.subplot(len(groups), 1, i)\n",
        "# \tpyplot.plot(values[:, group])\n",
        "# \tpyplot.title(dataset.columns[group], y=0.5, loc='right')\n",
        "# \ti += 1\n",
        "# pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccuaWFsXWYMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from pandas import DataFrame\n",
        "import pandas\n",
        "\n",
        "# convert series to supervised learning\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdf = DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = pandas.concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B4yxJ8PhcQD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "fac05f4e-d475-48a2-c0f7-718ea328810e"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "dataset = read_csv('pollution.csv', header=0, index_col=0)\n",
        "values = dataset.values\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "values[:,4] = encoder.fit_transform(values[:,4])\n",
        "\n",
        "values = values.astype('float32')\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled = scaler.fit_transform(values)\n",
        "\n",
        "reframed = series_to_supervised(scaled, 1, 1)\n",
        "\n",
        "reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)\n",
        "print(reframed.head())"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   var1(t-1)  var2(t-1)  var3(t-1)  ...  var7(t-1)  var8(t-1)   var1(t)\n",
            "1   0.129779   0.352941   0.245902  ...   0.000000        0.0  0.148893\n",
            "2   0.148893   0.367647   0.245902  ...   0.000000        0.0  0.159960\n",
            "3   0.159960   0.426471   0.229508  ...   0.000000        0.0  0.182093\n",
            "4   0.182093   0.485294   0.229508  ...   0.037037        0.0  0.138833\n",
            "5   0.138833   0.485294   0.229508  ...   0.074074        0.0  0.109658\n",
            "\n",
            "[5 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOcDLW3bjwGl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0a12cc38-1198-43a9-80cd-7981e2c6d290"
      },
      "source": [
        "# split into train and test sets\n",
        "values = reframed.values\n",
        "n_train_hours = 365 * 24 * 4\n",
        "train = values[:n_train_hours, :]\n",
        "test = values[n_train_hours:, :]\n",
        "\n",
        "print(train.shape)\n",
        "# split into input and outputs\n",
        "train_X, train_y = train[:, :-1], train[:, -1]\n",
        "test_X, test_y = test[:, :-1], test[:, -1]\n",
        "\n",
        "# reshape input to be 3D [samples, timesteps, features]\n",
        "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
        "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
        "\n",
        "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35040, 9)\n",
            "(35040, 1, 8) (35040,) (8759, 1, 8) (8759,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08YCnFUpk653",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6e5bffe9-ab5c-47e4-838d-5acadd47dcfd"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "# Network\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mae', optimizer='adam')\n",
        "\n",
        "# fit network\n",
        "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 35040 samples, validate on 8759 samples\n",
            "Epoch 1/50\n",
            " - 3s - loss: 0.0345 - val_loss: 0.0343\n",
            "Epoch 2/50\n",
            " - 1s - loss: 0.0143 - val_loss: 0.0143\n",
            "Epoch 3/50\n",
            " - 1s - loss: 0.0140 - val_loss: 0.0134\n",
            "Epoch 4/50\n",
            " - 1s - loss: 0.0140 - val_loss: 0.0131\n",
            "Epoch 5/50\n",
            " - 1s - loss: 0.0139 - val_loss: 0.0132\n",
            "Epoch 6/50\n",
            " - 1s - loss: 0.0139 - val_loss: 0.0132\n",
            "Epoch 7/50\n",
            " - 1s - loss: 0.0139 - val_loss: 0.0136\n",
            "Epoch 8/50\n",
            " - 1s - loss: 0.0139 - val_loss: 0.0138\n",
            "Epoch 9/50\n",
            " - 1s - loss: 0.0139 - val_loss: 0.0137\n",
            "Epoch 10/50\n",
            " - 1s - loss: 0.0139 - val_loss: 0.0137\n",
            "Epoch 11/50\n",
            " - 1s - loss: 0.0139 - val_loss: 0.0137\n",
            "Epoch 12/50\n",
            " - 1s - loss: 0.0139 - val_loss: 0.0137\n",
            "Epoch 13/50\n",
            " - 1s - loss: 0.0138 - val_loss: 0.0138\n",
            "Epoch 14/50\n",
            " - 1s - loss: 0.0138 - val_loss: 0.0136\n",
            "Epoch 15/50\n",
            " - 1s - loss: 0.0138 - val_loss: 0.0138\n",
            "Epoch 16/50\n",
            " - 1s - loss: 0.0138 - val_loss: 0.0140\n",
            "Epoch 17/50\n",
            " - 1s - loss: 0.0138 - val_loss: 0.0138\n",
            "Epoch 18/50\n",
            " - 1s - loss: 0.0138 - val_loss: 0.0139\n",
            "Epoch 19/50\n",
            " - 1s - loss: 0.0138 - val_loss: 0.0137\n",
            "Epoch 20/50\n",
            " - 1s - loss: 0.0138 - val_loss: 0.0137\n",
            "Epoch 21/50\n",
            " - 1s - loss: 0.0138 - val_loss: 0.0140\n",
            "Epoch 22/50\n",
            " - 1s - loss: 0.0138 - val_loss: 0.0136\n",
            "Epoch 23/50\n",
            " - 1s - loss: 0.0138 - val_loss: 0.0138\n",
            "Epoch 24/50\n",
            " - 1s - loss: 0.0138 - val_loss: 0.0140\n",
            "Epoch 25/50\n",
            " - 1s - loss: 0.0137 - val_loss: 0.0141\n",
            "Epoch 26/50\n",
            " - 1s - loss: 0.0137 - val_loss: 0.0144\n",
            "Epoch 27/50\n",
            " - 1s - loss: 0.0137 - val_loss: 0.0138\n",
            "Epoch 28/50\n",
            " - 1s - loss: 0.0137 - val_loss: 0.0140\n",
            "Epoch 29/50\n",
            " - 1s - loss: 0.0137 - val_loss: 0.0144\n",
            "Epoch 30/50\n",
            " - 1s - loss: 0.0137 - val_loss: 0.0153\n",
            "Epoch 31/50\n",
            " - 1s - loss: 0.0137 - val_loss: 0.0153\n",
            "Epoch 32/50\n",
            " - 1s - loss: 0.0137 - val_loss: 0.0141\n",
            "Epoch 33/50\n",
            " - 1s - loss: 0.0137 - val_loss: 0.0146\n",
            "Epoch 34/50\n",
            " - 1s - loss: 0.0137 - val_loss: 0.0150\n",
            "Epoch 35/50\n",
            " - 1s - loss: 0.0137 - val_loss: 0.0153\n",
            "Epoch 36/50\n",
            " - 1s - loss: 0.0137 - val_loss: 0.0153\n",
            "Epoch 37/50\n",
            " - 1s - loss: 0.0137 - val_loss: 0.0152\n",
            "Epoch 38/50\n",
            " - 1s - loss: 0.0137 - val_loss: 0.0150\n",
            "Epoch 39/50\n",
            " - 1s - loss: 0.0138 - val_loss: 0.0151\n",
            "Epoch 40/50\n",
            " - 1s - loss: 0.0137 - val_loss: 0.0145\n",
            "Epoch 41/50\n",
            " - 1s - loss: 0.0137 - val_loss: 0.0144\n",
            "Epoch 42/50\n",
            " - 1s - loss: 0.0137 - val_loss: 0.0144\n",
            "Epoch 43/50\n",
            " - 1s - loss: 0.0137 - val_loss: 0.0143\n",
            "Epoch 44/50\n",
            " - 1s - loss: 0.0137 - val_loss: 0.0144\n",
            "Epoch 45/50\n",
            " - 1s - loss: 0.0137 - val_loss: 0.0143\n",
            "Epoch 46/50\n",
            " - 1s - loss: 0.0136 - val_loss: 0.0140\n",
            "Epoch 47/50\n",
            " - 1s - loss: 0.0136 - val_loss: 0.0141\n",
            "Epoch 48/50\n",
            " - 1s - loss: 0.0136 - val_loss: 0.0139\n",
            "Epoch 49/50\n",
            " - 1s - loss: 0.0136 - val_loss: 0.0142\n",
            "Epoch 50/50\n",
            " - 1s - loss: 0.0136 - val_loss: 0.0145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE7w29rsl4vo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "d112488a-a66d-451a-a1f8-9c3d738ce360"
      },
      "source": [
        "# plot history\n",
        "from matplotlib import pyplot\n",
        "\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRa0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiMh7eD5ld5t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "457077ac-5dbd-4535-8beb-85741b3524d3"
      },
      "source": [
        "from math import sqrt\n",
        "from numpy import concatenate\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# make a prediction\n",
        "print(test_X.shape)\n",
        "# test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
        "yhat = model.predict(test_X)\n",
        "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
        "# invert scaling for forecast\n",
        "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
        "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "inv_yhat = inv_yhat[:,0]\n",
        "# invert scaling for actual\n",
        "test_y = test_y.reshape((len(test_y), 1))\n",
        "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
        "inv_y = scaler.inverse_transform(inv_y)\n",
        "inv_y = inv_y[:,0]\n",
        "# calculate RMSE\n",
        "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "print('Test RMSE: %.3f' % rmse)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8759, 1, 8)\n",
            "Test RMSE: 25.943\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRID_LSTM_on_PM2_5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gagandt/modelling-air-pollution/blob/master/multivariate/GRID_LSTM_on_PM2_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsUPIuOTe2J4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22203989-8090-42ae-f0ed-ef7cb650841f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccuaWFsXWYMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas import DataFrame\n",
        "import pandas\n",
        "from pandas import concat\n",
        "\n",
        "# convert series to supervised learning\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdf = DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOcDLW3bjwGl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4524834a-2e68-415d-ad36-5b57f78b6942"
      },
      "source": [
        "import os\n",
        "from pandas import read_csv\n",
        "from datetime import datetime\n",
        "# load data\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks')\n",
        "def parse(x):\n",
        "\treturn datetime.strptime(x, '%Y %m %d %H')\n",
        "dataset = read_csv('./data/beijing.csv',  parse_dates = [['year', 'month', 'day', 'hour']], index_col=0, date_parser=parse)\n",
        "dataset.drop('No', axis=1, inplace=True)\n",
        "# manually specify column names\n",
        "dataset.columns = ['pollution', 'dew', 'temp', 'press', 'wnd_dir', 'wnd_spd', 'snow', 'rain']\n",
        "dataset.index.name = 'date'\n",
        "# mark all NA values with 0\n",
        "dataset['pollution'].fillna(0, inplace=True)\n",
        "# drop the first 24 hours\n",
        "dataset = dataset[24:]\n",
        "# summarize first 5 rows\n",
        "print(dataset.head(5))\n",
        "# save to file\n",
        "dataset.to_csv('pollution.csv')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                     pollution  dew  temp   press wnd_dir  wnd_spd  snow  rain\n",
            "date                                                                          \n",
            "2010-01-02 00:00:00      129.0  -16  -4.0  1020.0      SE     1.79     0     0\n",
            "2010-01-02 01:00:00      148.0  -15  -4.0  1020.0      SE     2.68     0     0\n",
            "2010-01-02 02:00:00      159.0  -11  -5.0  1021.0      SE     3.57     0     0\n",
            "2010-01-02 03:00:00      181.0   -7  -5.0  1022.0      SE     5.36     1     0\n",
            "2010-01-02 04:00:00      138.0   -7  -5.0  1022.0      SE     6.25     2     0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmrHMLa5MwK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "import keras\n",
        "from math import sqrt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "def grid_search(dataset, lookback, nodes, layers, batch_sizes, split_percentage):\n",
        "  scores = list()\n",
        "  \n",
        "  for lookback_period in lookback:\n",
        "    values = series_to_supervised(dataset, lookback_period, 1).values\n",
        "    \n",
        "    n_train_hours = (int)(split_percentage * len(values))\n",
        "    train = values[:n_train_hours, :]\n",
        "    test = values[n_train_hours:, :]\n",
        "    \n",
        "    n_features = 8\n",
        "    n_hours = lookback_period\n",
        "    n_obs = n_hours * n_features\n",
        "    train_X, train_y = train[:, :n_obs], train[:, -n_features]\n",
        "    test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
        "\n",
        "    # reshape input to be 3D [samples, timesteps, features]\n",
        "    train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
        "    test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
        "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
        "    \n",
        "    for number_of_nodes in nodes:\n",
        "      \n",
        "      for number_of_layers in layers:\n",
        "        model = Sequential()\n",
        "        for i in range(number_of_layers):\n",
        "          if i == 0 :\n",
        "            model.add(LSTM(number_of_nodes, return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "          elif i == number_of_layers - 1 :\n",
        "            model.add(LSTM(number_of_nodes))\n",
        "          else :\n",
        "            model.add(LSTM(number_of_nodes, return_sequences=True))\n",
        "        \n",
        "        model.add(Dense(1))\n",
        "        model.compile(loss='mae', optimizer='adam')\n",
        "        \n",
        "        ref_model = copy.deepcopy(model)\n",
        "        \n",
        "        for batch_size in batch_sizes:\n",
        "          for number_of_epochs in epochs:         \n",
        "            model = copy.deepcopy(ref_model)\n",
        "\n",
        "            name = str(lookback_period)+'_'+str(number_of_nodes)+'_'+str(number_of_layers)+'_'+str(batch_size)+'_'+str(number_of_epochs)\n",
        "            print(\"Starting training for : \", name)\n",
        "            \n",
        "            history = model.fit(train_X, train_y, epochs=number_of_epochs, batch_size=batch_size, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
        "            yhat = model.predict(test_X)\n",
        "\n",
        "            np.save('LSTM_runtime/history/' + name, history)\n",
        "            np.save('LSTM_runtime/test_y/' + name, test_y)\n",
        "            np.save('LSTM_runtime/yhat/' + name, yhat)\n",
        "            \n",
        "            rmse = mean_squared_error(yhat, test_y)\n",
        "            print(\"RMSE for \", name, \" = \" , rmse)\n",
        "\n",
        "            scores.append([rmse, lookback_period, number_of_nodes, number_of_layers, batch_size, number_of_epochs])\n",
        "            np.save('LSTM_scores', np.array(scores))\n",
        "            keras.backend.clear_session()\n",
        "  return scores\n",
        "          \n",
        "  "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei1UVrcEkbrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# load dataset\n",
        "dataset = read_csv('pollution.csv', header=0, index_col=0)\n",
        "values = dataset.values\n",
        "\n",
        "# integer encode direction\n",
        "encoder = LabelEncoder()\n",
        "values[:,4] = encoder.fit_transform(values[:,4])\n",
        "\n",
        "# ensure all data is float\n",
        "values = values.astype('float32')\n",
        "\n",
        "# normalize features\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled = scaler.fit_transform(values)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLtlf_6lbPuI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bdabc998-b9b7-4752-d723-a6c1f41bd11a"
      },
      "source": [
        "layers = [2,4,16,32]\n",
        "lookback = [1,3,5,7]\n",
        "nodes = [25,50,75]\n",
        "# batch_size = [50, 75, 100]\n",
        "batch_size = [50, 75, 100]\n",
        "# epochs = [50, 100]\n",
        "epochs = [1]\n",
        "split_percentage = 0.8\n",
        "\n",
        "scores = grid_search(values, lookback, nodes, layers, batch_size, split_percentage)\n",
        "print(scores)\n",
        "np.save('LSTM_scores', np.array(scores))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35039, 1, 8) (35039,) (8760, 1, 8) (8760,)\n",
            "Starting training for :  1_25_2_50_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 3s - loss: 84.4813 - val_loss: 80.7208\n",
            "RMSE for  1_25_2_50_1  =  14814.869\n",
            "Starting training for :  1_25_2_75_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 2s - loss: 86.7322 - val_loss: 83.5735\n",
            "RMSE for  1_25_2_75_1  =  15483.91\n",
            "Starting training for :  1_25_2_100_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 2s - loss: 88.1236 - val_loss: 85.4205\n",
            "RMSE for  1_25_2_100_1  =  15890.61\n",
            "Starting training for :  1_25_4_50_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 4s - loss: 83.7826 - val_loss: 80.6693\n",
            "RMSE for  1_25_4_50_1  =  14800.976\n",
            "Starting training for :  1_25_4_75_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 3s - loss: 85.7248 - val_loss: 83.1754\n",
            "RMSE for  1_25_4_75_1  =  15394.004\n",
            "Starting training for :  1_25_4_100_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 3s - loss: 86.9207 - val_loss: 84.6597\n",
            "RMSE for  1_25_4_100_1  =  15725.737\n",
            "Starting training for :  1_25_16_50_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 16s - loss: 83.2364 - val_loss: 80.1961\n",
            "RMSE for  1_25_16_50_1  =  14683.792\n",
            "Starting training for :  1_25_16_75_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 14s - loss: 85.1325 - val_loss: 82.5041\n",
            "RMSE for  1_25_16_75_1  =  15239.9795\n",
            "Starting training for :  1_25_16_100_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 12s - loss: 86.3640 - val_loss: 83.9283\n",
            "RMSE for  1_25_16_100_1  =  15563.943\n",
            "Starting training for :  1_25_32_50_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 35s - loss: 83.8725 - val_loss: 80.7926\n",
            "RMSE for  1_25_32_50_1  =  14831.026\n",
            "Starting training for :  1_25_32_75_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 29s - loss: 85.7861 - val_loss: 83.2348\n",
            "RMSE for  1_25_32_75_1  =  15407.635\n",
            "Starting training for :  1_25_32_100_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 26s - loss: 86.9920 - val_loss: 84.7182\n",
            "RMSE for  1_25_32_100_1  =  15738.72\n",
            "Starting training for :  1_50_2_50_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 3s - loss: 79.4369 - val_loss: 74.2887\n",
            "RMSE for  1_50_2_50_1  =  13102.866\n",
            "Starting training for :  1_50_2_75_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 2s - loss: 81.9138 - val_loss: 77.1549\n",
            "RMSE for  1_50_2_75_1  =  13901.46\n",
            "Starting training for :  1_50_2_100_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 2s - loss: 83.5901 - val_loss: 79.0409\n",
            "RMSE for  1_50_2_100_1  =  14401.295\n",
            "Starting training for :  1_50_4_50_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 5s - loss: 79.0297 - val_loss: 74.6692\n",
            "RMSE for  1_50_4_50_1  =  13206.881\n",
            "Starting training for :  1_50_4_75_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 4s - loss: 81.2155 - val_loss: 77.3775\n",
            "RMSE for  1_50_4_75_1  =  13956.538\n",
            "Starting training for :  1_50_4_100_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 3s - loss: 82.6258 - val_loss: 79.0738\n",
            "RMSE for  1_50_4_100_1  =  14400.611\n",
            "Starting training for :  1_50_16_50_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 21s - loss: 78.8588 - val_loss: 74.4467\n",
            "RMSE for  1_50_16_50_1  =  13142.912\n",
            "Starting training for :  1_50_16_75_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 17s - loss: 81.0440 - val_loss: 77.0481\n",
            "RMSE for  1_50_16_75_1  =  13868.602\n",
            "Starting training for :  1_50_16_100_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 17s - loss: 82.4348 - val_loss: 78.5926\n",
            "RMSE for  1_50_16_100_1  =  14276.726\n",
            "Starting training for :  1_50_32_50_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 43s - loss: 79.0305 - val_loss: 74.5648\n",
            "RMSE for  1_50_32_50_1  =  13176.971\n",
            "Starting training for :  1_50_32_75_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 36s - loss: 81.2368 - val_loss: 77.2125\n",
            "RMSE for  1_50_32_75_1  =  13912.639\n",
            "Starting training for :  1_50_32_100_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 31s - loss: 82.6305 - val_loss: 78.7929\n",
            "RMSE for  1_50_32_100_1  =  14328.962\n",
            "Starting training for :  1_75_2_50_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 3s - loss: 76.2151 - val_loss: 66.2478\n",
            "RMSE for  1_75_2_50_1  =  11785.466\n",
            "Starting training for :  1_75_2_75_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 3s - loss: 78.9215 - val_loss: 70.7619\n",
            "RMSE for  1_75_2_75_1  =  12740.5\n",
            "Starting training for :  1_75_2_100_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 2s - loss: 81.0166 - val_loss: 75.2548\n",
            "RMSE for  1_75_2_100_1  =  13401.152\n",
            "Starting training for :  1_75_4_50_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 6s - loss: 76.3626 - val_loss: 71.4440\n",
            "RMSE for  1_75_4_50_1  =  12240.078\n",
            "Starting training for :  1_75_4_75_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 5s - loss: 78.6000 - val_loss: 74.0646\n",
            "RMSE for  1_75_4_75_1  =  13034.974\n",
            "Starting training for :  1_75_4_100_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 5s - loss: 80.0570 - val_loss: 75.7569\n",
            "RMSE for  1_75_4_100_1  =  13514.442\n",
            "Starting training for :  1_75_16_50_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 24s - loss: 76.2041 - val_loss: 71.1942\n",
            "RMSE for  1_75_16_50_1  =  12161.087\n",
            "Starting training for :  1_75_16_75_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 21s - loss: 78.4746 - val_loss: 73.6911\n",
            "RMSE for  1_75_16_75_1  =  12923.28\n",
            "Starting training for :  1_75_16_100_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 20s - loss: 79.9642 - val_loss: 75.2553\n",
            "RMSE for  1_75_16_100_1  =  13373.066\n",
            "Starting training for :  1_75_32_50_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 49s - loss: 75.8844 - val_loss: 71.0013\n",
            "RMSE for  1_75_32_50_1  =  12099.383\n",
            "Starting training for :  1_75_32_75_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 44s - loss: 78.1288 - val_loss: 73.4165\n",
            "RMSE for  1_75_32_75_1  =  12841.682\n",
            "Starting training for :  1_75_32_100_1\n",
            "Train on 35039 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 38s - loss: 79.5771 - val_loss: 74.8673\n",
            "RMSE for  1_75_32_100_1  =  13262.998\n",
            "(35037, 3, 8) (35037,) (8760, 3, 8) (8760,)\n",
            "Starting training for :  3_25_2_50_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 3s - loss: 82.3565 - val_loss: 78.9438\n",
            "RMSE for  3_25_2_50_1  =  14367.566\n",
            "Starting training for :  3_25_2_75_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 3s - loss: 84.3320 - val_loss: 81.6514\n",
            "RMSE for  3_25_2_75_1  =  15039.254\n",
            "Starting training for :  3_25_2_100_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 2s - loss: 85.5694 - val_loss: 83.3325\n",
            "RMSE for  3_25_2_100_1  =  15429.965\n",
            "Starting training for :  3_25_4_50_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 6s - loss: 82.5393 - val_loss: 79.2537\n",
            "RMSE for  3_25_4_50_1  =  14446.732\n",
            "Starting training for :  3_25_4_75_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 5s - loss: 84.4802 - val_loss: 81.9801\n",
            "RMSE for  3_25_4_75_1  =  15117.485\n",
            "Starting training for :  3_25_4_100_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 4s - loss: 85.6687 - val_loss: 83.6706\n",
            "RMSE for  3_25_4_100_1  =  15505.786\n",
            "Starting training for :  3_25_16_50_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 27s - loss: 81.4088 - val_loss: 78.2158\n",
            "RMSE for  3_25_16_50_1  =  14178.86\n",
            "Starting training for :  3_25_16_75_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 21s - loss: 83.2866 - val_loss: 80.7204\n",
            "RMSE for  3_25_16_75_1  =  14813.418\n",
            "Starting training for :  3_25_16_100_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 19s - loss: 84.4749 - val_loss: 82.2158\n",
            "RMSE for  3_25_16_100_1  =  15172.424\n",
            "Starting training for :  3_25_32_50_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 52s - loss: 81.3031 - val_loss: 78.1585\n",
            "RMSE for  3_25_32_50_1  =  14163.695\n",
            "Starting training for :  3_25_32_75_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 44s - loss: 83.1665 - val_loss: 80.6660\n",
            "RMSE for  3_25_32_75_1  =  14800.164\n",
            "Starting training for :  3_25_32_100_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 38s - loss: 84.3507 - val_loss: 82.1642\n",
            "RMSE for  3_25_32_100_1  =  15160.366\n",
            "Starting training for :  3_50_2_50_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 4s - loss: 76.7529 - val_loss: 69.9024\n",
            "RMSE for  3_50_2_50_1  =  12346.503\n",
            "Starting training for :  3_50_2_75_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 3s - loss: 79.4214 - val_loss: 74.0956\n",
            "RMSE for  3_50_2_75_1  =  13344.168\n",
            "Starting training for :  3_50_2_100_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 3s - loss: 80.9974 - val_loss: 77.0890\n",
            "RMSE for  3_50_2_100_1  =  13885.61\n",
            "Starting training for :  3_50_4_50_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 8s - loss: 76.9880 - val_loss: 72.5907\n",
            "RMSE for  3_50_4_50_1  =  12605.79\n",
            "Starting training for :  3_50_4_75_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 7s - loss: 79.0745 - val_loss: 75.3307\n",
            "RMSE for  3_50_4_75_1  =  13394.745\n",
            "Starting training for :  3_50_4_100_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 6s - loss: 80.4240 - val_loss: 77.0550\n",
            "RMSE for  3_50_4_100_1  =  13870.53\n",
            "Starting training for :  3_50_16_50_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 34s - loss: 76.6481 - val_loss: 72.2677\n",
            "RMSE for  3_50_16_50_1  =  12495.266\n",
            "Starting training for :  3_50_16_75_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 30s - loss: 78.7570 - val_loss: 74.8580\n",
            "RMSE for  3_50_16_75_1  =  13260.345\n",
            "Starting training for :  3_50_16_100_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 28s - loss: 80.0837 - val_loss: 76.4277\n",
            "RMSE for  3_50_16_100_1  =  13699.895\n",
            "Starting training for :  3_50_32_50_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 71s - loss: 77.2358 - val_loss: 72.6684\n",
            "RMSE for  3_50_32_50_1  =  12617.317\n",
            "Starting training for :  3_50_32_75_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 60s - loss: 79.4127 - val_loss: 75.3805\n",
            "RMSE for  3_50_32_75_1  =  13408.438\n",
            "Starting training for :  3_50_32_100_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 52s - loss: 80.8115 - val_loss: 77.1029\n",
            "RMSE for  3_50_32_100_1  =  13883.512\n",
            "Starting training for :  3_75_2_50_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 6s - loss: 74.3482 - val_loss: 65.4177\n",
            "RMSE for  3_75_2_50_1  =  11457.802\n",
            "Starting training for :  3_75_2_75_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 5s - loss: 77.0011 - val_loss: 72.0890\n",
            "RMSE for  3_75_2_75_1  =  12451.289\n",
            "Starting training for :  3_75_2_100_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 5s - loss: 78.4813 - val_loss: 73.8985\n",
            "RMSE for  3_75_2_100_1  =  12987.916\n",
            "Starting training for :  3_75_4_50_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 12s - loss: 73.0532 - val_loss: 63.4586\n",
            "RMSE for  3_75_4_50_1  =  11051.347\n",
            "Starting training for :  3_75_4_75_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 10s - loss: 76.5964 - val_loss: 72.1168\n",
            "RMSE for  3_75_4_75_1  =  12449.274\n",
            "Starting training for :  3_75_4_100_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 9s - loss: 78.0174 - val_loss: 73.8639\n",
            "RMSE for  3_75_4_100_1  =  12974.4795\n",
            "Starting training for :  3_75_16_50_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 47s - loss: 74.5092 - val_loss: 69.5768\n",
            "RMSE for  3_75_16_50_1  =  11623.309\n",
            "Starting training for :  3_75_16_75_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 41s - loss: 76.6773 - val_loss: 71.9435\n",
            "RMSE for  3_75_16_75_1  =  12395.402\n",
            "Starting training for :  3_75_16_100_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 37s - loss: 78.1478 - val_loss: 73.6197\n",
            "RMSE for  3_75_16_100_1  =  12901.986\n",
            "Starting training for :  3_75_32_50_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 94s - loss: 74.3901 - val_loss: 69.5139\n",
            "RMSE for  3_75_32_50_1  =  11601.222\n",
            "Starting training for :  3_75_32_75_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 84s - loss: 76.5451 - val_loss: 71.8541\n",
            "RMSE for  3_75_32_75_1  =  12367.592\n",
            "Starting training for :  3_75_32_100_1\n",
            "Train on 35037 samples, validate on 8760 samples\n",
            "Epoch 1/1\n",
            " - 75s - loss: 77.9903 - val_loss: 73.4810\n",
            "RMSE for  3_75_32_100_1  =  12860.789\n",
            "(35036, 5, 8) (35036,) (8759, 5, 8) (8759,)\n",
            "Starting training for :  5_25_2_50_1\n",
            "Train on 35036 samples, validate on 8759 samples\n",
            "Epoch 1/1\n",
            " - 5s - loss: 82.1390 - val_loss: 78.9087\n",
            "RMSE for  5_25_2_50_1  =  14358.062\n",
            "Starting training for :  5_25_2_75_1\n",
            "Train on 35036 samples, validate on 8759 samples\n",
            "Epoch 1/1\n",
            " - 4s - loss: 84.0432 - val_loss: 81.5950\n",
            "RMSE for  5_25_2_75_1  =  15025.248\n",
            "Starting training for :  5_25_2_100_1\n",
            "Train on 35036 samples, validate on 8759 samples\n",
            "Epoch 1/1\n",
            " - 3s - loss: 85.2307 - val_loss: 83.2324\n",
            "RMSE for  5_25_2_100_1  =  15406.89\n",
            "Starting training for :  5_25_4_50_1\n",
            "Train on 35036 samples, validate on 8759 samples\n",
            "Epoch 1/1\n",
            " - 8s - loss: 81.3015 - val_loss: 78.3569\n",
            "RMSE for  5_25_4_50_1  =  14214.802\n",
            "Starting training for :  5_25_4_75_1\n",
            "Train on 35036 samples, validate on 8759 samples\n",
            "Epoch 1/1\n",
            " - 7s - loss: 83.0864 - val_loss: 80.8833\n",
            "RMSE for  5_25_4_75_1  =  14852.921\n",
            "Starting training for :  5_25_4_100_1\n",
            "Train on 35036 samples, validate on 8759 samples\n",
            "Epoch 1/1\n",
            " - 6s - loss: 84.1986 - val_loss: 82.4187\n",
            "RMSE for  5_25_4_100_1  =  15219.724\n",
            "Starting training for :  5_25_16_50_1\n",
            "Train on 35036 samples, validate on 8759 samples\n",
            "Epoch 1/1\n",
            " - 36s - loss: 81.3295 - val_loss: 78.3653\n",
            "RMSE for  5_25_16_50_1  =  14216.933\n",
            "Starting training for :  5_25_16_75_1\n",
            "Train on 35036 samples, validate on 8759 samples\n",
            "Epoch 1/1\n",
            " - 28s - loss: 83.1346 - val_loss: 80.8983\n",
            "RMSE for  5_25_16_75_1  =  14856.433\n",
            "Starting training for :  5_25_16_100_1\n",
            "Train on 35036 samples, validate on 8759 samples\n",
            "Epoch 1/1\n",
            " - 25s - loss: 84.2473 - val_loss: 82.3990\n",
            "RMSE for  5_25_16_100_1  =  15215.043\n",
            "Starting training for :  5_25_32_50_1\n",
            "Train on 35036 samples, validate on 8759 samples\n",
            "Epoch 1/1\n",
            " - 78s - loss: 81.8338 - val_loss: 78.7952\n",
            "RMSE for  5_25_32_50_1  =  14328.953\n",
            "Starting training for :  5_25_32_75_1\n",
            "Train on 35036 samples, validate on 8759 samples\n",
            "Epoch 1/1\n",
            " - 58s - loss: 83.6777 - val_loss: 81.4173\n",
            "RMSE for  5_25_32_75_1  =  14982.567\n",
            "Starting training for :  5_25_32_100_1\n",
            "Train on 35036 samples, validate on 8759 samples\n",
            "Epoch 1/1\n",
            " - 51s - loss: 84.7954 - val_loss: 82.9905\n",
            "RMSE for  5_25_32_100_1  =  15351.315\n",
            "Starting training for :  5_50_2_50_1\n",
            "Train on 35036 samples, validate on 8759 samples\n",
            "Epoch 1/1\n",
            " - 6s - loss: 76.9639 - val_loss: 72.1274\n",
            "RMSE for  5_50_2_50_1  =  12625.672\n",
            "Starting training for :  5_50_2_75_1\n",
            "Train on 35036 samples, validate on 8759 samples\n",
            "Epoch 1/1\n",
            " - 5s - loss: 78.9891 - val_loss: 73.9653\n",
            "RMSE for  5_50_2_75_1  =  13363.783\n",
            "Starting training for :  5_50_2_100_1\n",
            "Train on 35036 samples, validate on 8759 samples\n",
            "Epoch 1/1\n",
            " - 5s - loss: 80.4020 - val_loss: 77.0834\n",
            "RMSE for  5_50_2_100_1  =  13879.567\n",
            "Starting training for :  5_50_4_50_1\n",
            "Train on 35036 samples, validate on 8759 samples\n",
            "Epoch 1/1\n",
            " - 12s - loss: 77.1732 - val_loss: 72.8377\n",
            "RMSE for  5_50_4_50_1  =  12668.469\n",
            "Starting training for :  5_50_4_75_1\n",
            "Train on 35036 samples, validate on 8759 samples\n",
            "Epoch 1/1\n",
            " - 10s - loss: 79.2282 - val_loss: 75.5567\n",
            "RMSE for  5_50_4_75_1  =  13457.678\n",
            "Starting training for :  5_50_4_100_1\n",
            "Train on 35036 samples, validate on 8759 samples\n",
            "Epoch 1/1\n",
            " - 9s - loss: 80.5701 - val_loss: 77.3785\n",
            "RMSE for  5_50_4_100_1  =  13956.073\n",
            "Starting training for :  5_50_16_50_1\n",
            "Train on 35036 samples, validate on 8759 samples\n",
            "Epoch 1/1\n",
            " - 49s - loss: 77.0916 - val_loss: 72.7330\n",
            "RMSE for  5_50_16_50_1  =  12636.164\n",
            "Starting training for :  5_50_16_75_1\n",
            "Train on 35036 samples, validate on 8759 samples\n",
            "Epoch 1/1\n",
            " - 42s - loss: 79.1695 - val_loss: 75.4396\n",
            "RMSE for  5_50_16_75_1  =  13424.42\n",
            "Starting training for :  5_50_16_100_1\n",
            "Train on 35036 samples, validate on 8759 samples\n",
            "Epoch 1/1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
